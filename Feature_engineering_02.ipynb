{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering with tensorflow (notebook 02)\n",
    "\n",
    "These are my personal notes on the \"google cloud - feature engineering\" course on coursera (https://www.coursera.org/learn/feature-engineering). This notebook will continue where notebook 1 on this repo left off. Based on the same housing price dataset, this notebook will cover feature crossing and embeddings in tensorflow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "We will compare (the evaluation set loss of) **four** models for predicting house prices, where the first model serves as baseline for the others: \n",
    "\n",
    "1. Linear regressor // Data: house location (bucketized longtitude and latitude), median income of inhabitants, house properties (i.e., median age, rooms per house, bedrooms per room)\n",
    "2. Linear regressor // Data: Adding longitude x latitude feature crosses \n",
    "3. Linear regressor // Data: Substituting feature crosses with embeddings of longitude x latitude feature crosses  \n",
    "4. DNN regressor    // Data: Substituting feature crosses with embeddings of longitude x latitude feature crosses  \n",
    "\n",
    "We will use four general functions: \n",
    "\n",
    "- **add_features(df):** can be used to add additional features to the dataset (i.e., by combining existing features)\n",
    "- **make_input_fn(df, num_epochs):** creates a node in the comp graph that feeds the data. It calls add_features(df)\n",
    "- **create_feature_cols():** defines which features are passed to the model (and does some feature transformation, like one-hot-encoding) \n",
    "- **train_and_evaluate(output_dir, num_train_steps):** runs training and evaluation when called. Instantiates a model (linear regressor or DNN regressor) and calls the previous three functions  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A brief look at the data again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages \n",
    "import itertools\n",
    "import tensorflow as tf \n",
    "import tensorflow.feature_column as fc \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data into a pandas dataframe\n",
    "df = pd.read_csv(\"data\\california_housing_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns in the dataset\n",
    "- **longitude and latitude** -- long and lat values for the US West Coast area\n",
    "- **housing_median_age** -- median age of houses in the area\n",
    "- **total_rooms** -- total number of rooms of all houses in the area \n",
    "- **total_bedrooms** -- total number of bedrooms of all houses in the area\n",
    "- **population** -- total number of people living in the area\n",
    "- **households** -- total number of households in the area\n",
    "- **median_income** -- median income \n",
    "- **median_house_value** -- **value to be predicted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-114.31</td>\n",
       "      <td>34.19</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5612.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>1.4936</td>\n",
       "      <td>66900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-114.47</td>\n",
       "      <td>34.40</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>1901.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>1.8200</td>\n",
       "      <td>80100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-114.56</td>\n",
       "      <td>33.69</td>\n",
       "      <td>17.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.6509</td>\n",
       "      <td>85700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-114.57</td>\n",
       "      <td>33.64</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>3.1917</td>\n",
       "      <td>73400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-114.57</td>\n",
       "      <td>33.57</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1.9250</td>\n",
       "      <td>65500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
       "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
       "2    -114.56     33.69                17.0        720.0           174.0   \n",
       "3    -114.57     33.64                14.0       1501.0           337.0   \n",
       "4    -114.57     33.57                20.0       1454.0           326.0   \n",
       "\n",
       "   population  households  median_income  median_house_value  \n",
       "0      1015.0       472.0         1.4936             66900.0  \n",
       "1      1129.0       463.0         1.8200             80100.0  \n",
       "2       333.0       117.0         1.6509             85700.0  \n",
       "3       515.0       226.0         3.1917             73400.0  \n",
       "4       624.0       262.0         1.9250             65500.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A brief look at the summary statistics\n",
    "- no empty cells (17,000 entried for each column) \n",
    "- house values range between USD 15,000 - 500,000\n",
    "- longitude values range from -124 to -114\n",
    "- latitude values range from 32.5 to 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.562108</td>\n",
       "      <td>35.625225</td>\n",
       "      <td>28.589353</td>\n",
       "      <td>2643.664412</td>\n",
       "      <td>539.410824</td>\n",
       "      <td>1429.573941</td>\n",
       "      <td>501.221941</td>\n",
       "      <td>3.883578</td>\n",
       "      <td>207300.912353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.005166</td>\n",
       "      <td>2.137340</td>\n",
       "      <td>12.586937</td>\n",
       "      <td>2179.947071</td>\n",
       "      <td>421.499452</td>\n",
       "      <td>1147.852959</td>\n",
       "      <td>384.520841</td>\n",
       "      <td>1.908157</td>\n",
       "      <td>115983.764387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.790000</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1462.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>790.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>2.566375</td>\n",
       "      <td>119400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.490000</td>\n",
       "      <td>34.250000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>434.000000</td>\n",
       "      <td>1167.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.544600</td>\n",
       "      <td>180400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.000000</td>\n",
       "      <td>37.720000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3151.250000</td>\n",
       "      <td>648.250000</td>\n",
       "      <td>1721.000000</td>\n",
       "      <td>605.250000</td>\n",
       "      <td>4.767000</td>\n",
       "      <td>265000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.310000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>37937.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          longitude      latitude  housing_median_age   total_rooms  \\\n",
       "count  17000.000000  17000.000000        17000.000000  17000.000000   \n",
       "mean    -119.562108     35.625225           28.589353   2643.664412   \n",
       "std        2.005166      2.137340           12.586937   2179.947071   \n",
       "min     -124.350000     32.540000            1.000000      2.000000   \n",
       "25%     -121.790000     33.930000           18.000000   1462.000000   \n",
       "50%     -118.490000     34.250000           29.000000   2127.000000   \n",
       "75%     -118.000000     37.720000           37.000000   3151.250000   \n",
       "max     -114.310000     41.950000           52.000000  37937.000000   \n",
       "\n",
       "       total_bedrooms    population    households  median_income  \\\n",
       "count    17000.000000  17000.000000  17000.000000   17000.000000   \n",
       "mean       539.410824   1429.573941    501.221941       3.883578   \n",
       "std        421.499452   1147.852959    384.520841       1.908157   \n",
       "min          1.000000      3.000000      1.000000       0.499900   \n",
       "25%        297.000000    790.000000    282.000000       2.566375   \n",
       "50%        434.000000   1167.000000    409.000000       3.544600   \n",
       "75%        648.250000   1721.000000    605.250000       4.767000   \n",
       "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
       "\n",
       "       median_house_value  \n",
       "count        17000.000000  \n",
       "mean        207300.912353  \n",
       "std         115983.764387  \n",
       "min          14999.000000  \n",
       "25%         119400.000000  \n",
       "50%         180400.000000  \n",
       "75%         265000.000000  \n",
       "max         500001.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into train and evaluation set \n",
    "def split_train_dev(train_split, df):\n",
    "    train_df = df.sample(frac=train_split,random_state=1)\n",
    "    dev_df = df.drop(train_df.index)\n",
    "    return train_df, dev_df\n",
    "\n",
    "train_df, eval_df = split_train_dev(0.8, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the linear and dnn regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHARED INPUT FUNCTIONS \n",
    "\n",
    "# input function \n",
    "def make_input_fn(df, num_epochs):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x = add_features(df),\n",
    "        y = df['median_house_value'] / 100000, # !!! \n",
    "        batch_size = 128,\n",
    "        num_epochs = num_epochs,\n",
    "        shuffle = True,\n",
    "        queue_capacity = 1000,\n",
    "        num_threads = 1\n",
    "    )\n",
    "\n",
    "# LINEAR REGRESSOR \n",
    "\n",
    "# Create estimator train and evaluate function\n",
    "def linear_train_and_evaluate(output_dir, num_train_steps):\n",
    "    \n",
    "    # Specify output directory  \n",
    "    run_config = tf.estimator.RunConfig(\n",
    "                 model_dir=output_dir,      \n",
    "                 save_summary_steps=100,                       \n",
    "                 save_checkpoints_steps=100)   # dictates max frequency of eval \n",
    "    \n",
    "    myopt = tf.train.FtrlOptimizer(learning_rate = 0.2) # note the learning rate \n",
    "    \n",
    "    # specify model \n",
    "    estimator = tf.estimator.LinearRegressor(config=run_config,\n",
    "                                             feature_columns = create_feature_cols(), \n",
    "                                             optimizer = myopt)\n",
    "    \n",
    "    #Add rmse evaluation metric\n",
    "    def rmse(labels, predictions):\n",
    "        pred_values = tf.cast(predictions['predictions'],tf.float64)\n",
    "        return {'rmse': tf.metrics.root_mean_squared_error(labels, pred_values)}\n",
    "    estimator = tf.contrib.estimator.add_metrics(estimator,rmse)\n",
    "    \n",
    "    # specify train set\n",
    "    train_spec = tf.estimator.TrainSpec(input_fn = make_input_fn(train_df, None), \n",
    "                                             max_steps = num_train_steps)\n",
    "    \n",
    "    # specify eval set \n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn = make_input_fn(eval_df, 1), \n",
    "                                    steps = None, \n",
    "                                    throttle_secs = 5)  # evaluates no more than every 5 seconds per second\n",
    "    \n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
    "    \n",
    "# DNN REGRESSOR \n",
    "\n",
    "def dnn_train_and_evaluate(output_dir, num_train_steps):\n",
    "    \n",
    "    # Specify output directory  \n",
    "    run_config = tf.estimator.RunConfig(\n",
    "                 model_dir=output_dir,      \n",
    "                 save_summary_steps=100,                       \n",
    "                 save_checkpoints_steps=100)   # dictates max frequency of eval \n",
    "    \n",
    "    # specify model \n",
    "    estimator = tf.estimator.DNNRegressor(hidden_units=[75, 25, 7],\n",
    "                                          config=run_config,\n",
    "                                          feature_columns = create_feature_cols(), \n",
    "                                          batch_norm=True)\n",
    "    \n",
    "    # specify train set\n",
    "    train_spec = tf.estimator.TrainSpec(input_fn = make_input_fn(train_df, None), \n",
    "                                             max_steps = num_train_steps)\n",
    "    \n",
    "    # specify eval set \n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn = make_input_fn(eval_df, 1), \n",
    "                                    steps = None, \n",
    "                                    throttle_secs = 5)  # evaluates no more than every 5 seconds per second\n",
    "    \n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature crosses\n",
    "\n",
    "**Idea:** Combine input features in such a way that the model does not have to explicitely learn their interactions/dependencies, but rather receives feature combinations as input. \n",
    "\n",
    "**For example,** in this dataset we have data for **latitude and longitude** for each sample. We then proceeded and put these values into **discrete buckets** grouping floating point values together roughly every 0.5 degrees. During training, the model \"learns\" weights to multiply these input features with to optimize the prediction loss.  \n",
    "\n",
    "**The issue with this method:** Let's assume there is a certain quadrant of land (at longitude 110.0-110.5 / latitude 33.0-33.5) where property prices are extremely high. In this case, the model cannot simply assign a very high weight to the longitude 110.0-110.5 bucket if slightly to the north of the high-value quandrant (let's say at longitude 110.0-110.5 / latitude 34.0-34.5) house prices are for some reason low. In other words, **only the combination of these two specific coordinates indicates high prices in this case.** While a linear model will not be able to \"learn\" this, a deep neural network can, though at the cost of complexity (i.e., compute power). \n",
    "\n",
    "If we instead **create new feature columns,** where each column consists of the multiplication of two specific longitudes/ latitude buckets (i.e., output == 1 if a property happens to fall into that specific area), then the model can easily attach a weight to every single quadrant that is described in this way. This means that even a simple linear model can learn to predict high prices for some quadrants and lower prices for others.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images\\feature_cross.jpg' width='1000' height='1000'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can thus expect that the linear model will close the performance gap to the neural network in our example (and potentially for our neural net to converge faster and require less depth/complexity)\n",
    "\n",
    "**The risk of feature crosses:** model can overfit if we present too many cominations of the same data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature crosses in tensorflow\n",
    "\n",
    "The method **tf.feature_column.crossed_column([<cat_column>, <cat_column>], nbuckets)** requires a list of categorical input columns. The number of buckets determines onto how many buckets the resulting feature cross combinations will be distributed.* \n",
    "- If the number of buckets specified matches exactly the number of category combinations from the feature columns, then each combination will end up in one column. \n",
    "- If the number of buckets specified is smaller than the number of category combinations from the feature columns, then multiple combinations will fall into the same column. This forces the model to generalize more. If it is larger, samples from one combination will be spread across multiple columns. This allows the model for a higher degree of \"memorizing\" the training data \n",
    "\n",
    " \n",
    "*intuitively, the method creates a hash for each feature cross combination which it then divides by the number of buckets (using the modulo operation) which assign it to a bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model: Linear regressor without feature crosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating some input features \n",
    "def add_features(df):\n",
    "    df['avg_rooms_per_house'] = df['total_rooms'] / df['households'] #expect positive correlation\n",
    "    df['avg_persons_per_room'] = df['population'] / df['total_rooms'] #expect negative correlation\n",
    "    df['avg_bedrooms_per_room'] = df['total_bedrooms'] / df['total_rooms'] # expect negative correlation \n",
    "    return df\n",
    "\n",
    "\n",
    "# Defining which features to include and bucketizing longitude and latitude\n",
    "def create_feature_cols():\n",
    "    \n",
    "    # define number of longitude and latitude buckets\n",
    "    num_buckets = 30 \n",
    "    long_buckets = np.linspace(-124.0, -114.5, num_buckets).tolist()\n",
    "    lat_buckets = np.linspace(32.0, 42, num_buckets).tolist()\n",
    "    \n",
    "    # define input features \n",
    "    return [\n",
    "    fc.bucketized_column(tf.feature_column.numeric_column('longitude'), \n",
    "                                        boundaries = long_buckets),  \n",
    "    fc.bucketized_column(tf.feature_column.numeric_column('latitude'), \n",
    "                                        boundaries = lat_buckets),\n",
    "    fc.numeric_column('median_income'),\n",
    "    fc.numeric_column('housing_median_age'),\n",
    "    fc.numeric_column('avg_rooms_per_house'),\n",
    "    fc.numeric_column('avg_persons_per_room'),\n",
    "    fc.numeric_column('avg_bedrooms_per_room')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'CHECKPOINTS/feat_eng_02/model_test', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000250B6C1DE10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'CHECKPOINTS/feat_eng_02/model_test', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000250BC76CF98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 100 or save_checkpoints_secs None.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 100 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:loss = 63.495564, step = 101\n",
      "INFO:tensorflow:Saving checkpoints for 200 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:36:12\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:36:13\n",
      "INFO:tensorflow:Saving dict for global step 200: average_loss = 0.52502173, global_step = 200, label/mean = 2.071208, loss = 66.113846, prediction/mean = 2.0773394, rmse = 0.7245838\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 200: CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-200\n",
      "INFO:tensorflow:global_step/sec: 19.21\n",
      "INFO:tensorflow:loss = 50.45878, step = 201 (5.209 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 300 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:36:17\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-300\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:36:18\n",
      "INFO:tensorflow:Saving dict for global step 300: average_loss = 0.51858014, global_step = 300, label/mean = 2.071208, loss = 65.30268, prediction/mean = 2.0774424, rmse = 0.7201251\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 300: CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-300\n",
      "INFO:tensorflow:global_step/sec: 27.0454\n",
      "INFO:tensorflow:loss = 71.17346, step = 301 (3.697 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 400 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 52.9787\n",
      "INFO:tensorflow:loss = 46.7389, step = 401 (1.891 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 74.9005\n",
      "INFO:tensorflow:loss = 46.20949, step = 501 (1.331 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 600 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:36:24\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:36:25\n",
      "INFO:tensorflow:Saving dict for global step 600: average_loss = 0.55952865, global_step = 600, label/mean = 2.071208, loss = 70.45916, prediction/mean = 2.2795687, rmse = 0.7480165\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 600: CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-600\n",
      "INFO:tensorflow:global_step/sec: 22.599\n",
      "INFO:tensorflow:loss = 69.429756, step = 601 (4.425 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 700 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 56.1944\n",
      "INFO:tensorflow:loss = 58.64065, step = 701 (1.781 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 800 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 77.4361\n",
      "INFO:tensorflow:loss = 54.76573, step = 801 (1.290 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 900 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:36:31\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-900\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:36:31\n",
      "INFO:tensorflow:Saving dict for global step 900: average_loss = 0.5053436, global_step = 900, label/mean = 2.071208, loss = 63.635864, prediction/mean = 2.1219249, rmse = 0.7108753\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 900: CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-900\n",
      "INFO:tensorflow:global_step/sec: 31.5305\n",
      "INFO:tensorflow:loss = 81.32645, step = 901 (3.171 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 60.5476\n",
      "INFO:tensorflow:loss = 52.032913, step = 1001 (1.653 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1100 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 71.8058\n",
      "INFO:tensorflow:loss = 64.49661, step = 1101 (1.392 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1200 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:36:38\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-1200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:36:38\n",
      "INFO:tensorflow:Saving dict for global step 1200: average_loss = 0.52076834, global_step = 1200, label/mean = 2.0712082, loss = 65.57824, prediction/mean = 2.2147079, rmse = 0.7216428\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1200: CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-1200\n",
      "INFO:tensorflow:global_step/sec: 25.1219\n",
      "INFO:tensorflow:loss = 51.80549, step = 1201 (3.986 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1300 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 36.4444\n",
      "INFO:tensorflow:loss = 56.90709, step = 1301 (2.737 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1400 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:36:44\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-1400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:36:45\n",
      "INFO:tensorflow:Saving dict for global step 1400: average_loss = 0.5091816, global_step = 1400, label/mean = 2.071208, loss = 64.11917, prediction/mean = 1.9413556, rmse = 0.71356964\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1400: CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-1400\n",
      "INFO:tensorflow:global_step/sec: 28.1491\n",
      "INFO:tensorflow:loss = 55.400097, step = 1401 (3.555 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1500 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 47.2631\n",
      "INFO:tensorflow:loss = 46.062065, step = 1501 (2.116 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1600 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:36:50\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-1600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:36:51\n",
      "INFO:tensorflow:Saving dict for global step 1600: average_loss = 0.49596542, global_step = 1600, label/mean = 2.071208, loss = 62.454906, prediction/mean = 2.0070376, rmse = 0.70424813\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1600: CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-1600\n",
      "INFO:tensorflow:global_step/sec: 24.0864\n",
      "INFO:tensorflow:loss = 62.34752, step = 1601 (4.155 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1700 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 46.9867\n",
      "INFO:tensorflow:loss = 46.44316, step = 1701 (2.123 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1800 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:36:57\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-1800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:36:58\n",
      "INFO:tensorflow:Saving dict for global step 1800: average_loss = 0.49528676, global_step = 1800, label/mean = 2.071208, loss = 62.369442, prediction/mean = 2.122093, rmse = 0.7037661\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1800: CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-1800\n",
      "INFO:tensorflow:global_step/sec: 23.1123\n",
      "INFO:tensorflow:loss = 61.75658, step = 1801 (4.329 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1900 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 52.1186\n",
      "INFO:tensorflow:loss = 55.40528, step = 1901 (1.921 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:37:02\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:37:03\n",
      "INFO:tensorflow:Saving dict for global step 2000: average_loss = 0.49074456, global_step = 2000, label/mean = 2.0712078, loss = 61.797462, prediction/mean = 2.0924296, rmse = 0.7005316\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-2000\n",
      "INFO:tensorflow:global_step/sec: 26.3116\n",
      "INFO:tensorflow:loss = 56.140812, step = 2001 (3.797 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2100 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 39.0515\n",
      "INFO:tensorflow:loss = 50.77825, step = 2101 (2.560 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2200 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:37:09\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-2200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:37:09\n",
      "INFO:tensorflow:Saving dict for global step 2200: average_loss = 0.48919025, global_step = 2200, label/mean = 2.071208, loss = 61.601734, prediction/mean = 2.0757291, rmse = 0.69942135\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2200: CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-2200\n",
      "INFO:tensorflow:global_step/sec: 28.3871\n",
      "INFO:tensorflow:loss = 52.48016, step = 2201 (3.525 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2300 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 41.8853\n",
      "INFO:tensorflow:loss = 64.31888, step = 2301 (2.385 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2400 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:37:15\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-2400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:37:15\n",
      "INFO:tensorflow:Saving dict for global step 2400: average_loss = 0.5123871, global_step = 2400, label/mean = 2.0712082, loss = 64.52282, prediction/mean = 2.2154768, rmse = 0.71581215\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2400: CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.4461\n",
      "INFO:tensorflow:loss = 50.799107, step = 2401 (3.515 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2500 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 55.1445\n",
      "INFO:tensorflow:loss = 52.160694, step = 2501 (1.815 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2600 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:37:20\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-2600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:37:21\n",
      "INFO:tensorflow:Saving dict for global step 2600: average_loss = 0.49701285, global_step = 2600, label/mean = 2.0712082, loss = 62.586807, prediction/mean = 2.1641552, rmse = 0.7049914\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2600: CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-2600\n",
      "INFO:tensorflow:global_step/sec: 26.7998\n",
      "INFO:tensorflow:loss = 56.50732, step = 2601 (3.730 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2700 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 44.5988\n",
      "INFO:tensorflow:loss = 66.75926, step = 2701 (2.244 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2800 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:37:26\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-2800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:37:27\n",
      "INFO:tensorflow:Saving dict for global step 2800: average_loss = 0.48547992, global_step = 2800, label/mean = 2.071208, loss = 61.134506, prediction/mean = 2.069827, rmse = 0.6967639\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2800: CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-2800\n",
      "INFO:tensorflow:global_step/sec: 22.9595\n",
      "INFO:tensorflow:loss = 56.707287, step = 2801 (4.358 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2900 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:37:32\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-2900\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:37:33\n",
      "INFO:tensorflow:Saving dict for global step 2900: average_loss = 0.4943992, global_step = 2900, label/mean = 2.071208, loss = 62.257675, prediction/mean = 2.15838, rmse = 0.70313525\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2900: CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-2900\n",
      "INFO:tensorflow:global_step/sec: 17.0317\n",
      "INFO:tensorflow:loss = 45.39492, step = 2901 (5.867 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into CHECKPOINTS/feat_eng_02/model_test\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:37:37\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:37:38\n",
      "INFO:tensorflow:Saving dict for global step 3000: average_loss = 0.48928383, global_step = 3000, label/mean = 2.0712082, loss = 61.61352, prediction/mean = 2.1292748, rmse = 0.6994883\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: CHECKPOINTS/feat_eng_02/model_test\\model.ckpt-3000\n",
      "INFO:tensorflow:Loss for final step: 48.99452.\n"
     ]
    }
   ],
   "source": [
    "# prevent verbose output\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# run baseline model\n",
    "linear_train_and_evaluate(output_dir='CHECKPOINTS/feat_eng_02/model_test', num_train_steps = 3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the baseline loss achieved by the first model on the evaluation set\n",
    "\n",
    "<img src='images\\feature_eng2_base.PNG' width='600' height='600'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Linear regressor with feature cross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we are adding a feature cross between the bucketized values of longitude and latitude. Each new feature consists of a unique combination of longitude (e.g., 123.5-124) and latitude (e.g., 34.5-35) that in this case make up a physical area on a map. Each sample from the housing data falls into exactly one of those areas.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new input features \n",
    "def add_features(df):\n",
    "    df['avg_rooms_per_house'] = df['total_rooms'] / df['households'] #expect positive correlation\n",
    "    df['avg_persons_per_room'] = df['population'] / df['total_rooms'] #expect negative correlation\n",
    "    df['avg_bedrooms_per_room'] = df['total_bedrooms'] / df['total_rooms'] # expect negative correlation \n",
    "    return df\n",
    "\n",
    "\n",
    "# Add feature cross\n",
    "def create_feature_cols():\n",
    "    num_buckets = 30 \n",
    "    long_buckets = np.linspace(-124.0, -114.5, num_buckets).tolist()\n",
    "    lat_buckets = np.linspace(32.0, 42, num_buckets).tolist()\n",
    "    \n",
    "    b_long = fc.bucketized_column(fc.numeric_column('longitude'), long_buckets)  \n",
    "    b_lat = fc.bucketized_column(fc.numeric_column('latitude'), lat_buckets)\n",
    "    \n",
    "    return [\n",
    "    # add feature cross\n",
    "    fc.crossed_column([b_lat, b_long], num_buckets**2), \n",
    "    # add other features \n",
    "    fc.numeric_column('median_income'),\n",
    "    fc.numeric_column('housing_median_age'),\n",
    "    fc.numeric_column('avg_rooms_per_house'),\n",
    "    fc.numeric_column('avg_persons_per_room'),\n",
    "    fc.numeric_column('avg_bedrooms_per_room')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model 2\n",
    "linear_train_and_evaluate(output_dir='CHECKPOINTS/feat_eng_02/model_2', num_train_steps = 3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the average loss output recorded during training (chart below), we see a clear improvement from adding the feature crosses (light blue line) relative to the original baseline (dark blue line)\n",
    "\n",
    "<img src='images\\feature_eng2_model_2.PNG' width='600' height='600'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why embeddings:** \n",
    "\n",
    "The issue with feature crosses is that they create a very **sparse encoding**, i.e., for each sample in the dataset we have hundreds of possible longitude / latitude bucket combinations, of which exactly one has a value of 1 (i.e., the bucket that correpsonds to the area where the house is in) while all the others have a value of 0. Embeddings translate this sparse representation into something more dense (and meaningful):\n",
    "\n",
    "Rather than feeding the regressor with all the hundreds of feature cross values, we run those through a dense layer with one or more neurons, which then feed into the network. Like any other parameter, the model trains the weights of this dense layer with respect to the objective function (i.e., in our case minimizing the loss from the difference between predicted and actual house prices).  \n",
    "\n",
    "Each embedding feature is a real floating point number (the weighted sum of feature crosses). Feature crosses (in our case areas of land) that are similar to each other in ways that determine house prices, will receive similar values from this embedding exercise. Crucially, when looking at a new sample, the weights applied to its location will make the model treat it similarly to other houses from the same location (at least with respect to the impact of location on house prices). \n",
    "\n",
    "Embeddings are a critical part to recommendation engines (e.g., movies on netflix) or natural language models (e.g., google translate).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substituting the raw feature crosses with embeddings in our input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new input features \n",
    "def add_features(df):\n",
    "    df['avg_rooms_per_house'] = df['total_rooms'] / df['households'] #expect positive correlation\n",
    "    df['avg_persons_per_room'] = df['population'] / df['total_rooms'] #expect negative correlation\n",
    "    df['avg_bedrooms_per_room'] = df['total_bedrooms'] / df['total_rooms'] # expect negative correlation \n",
    "    return df\n",
    "\n",
    "\n",
    "# Add feature cross\n",
    "def create_feature_cols():\n",
    "    num_buckets = 30 \n",
    "    long_buckets = np.linspace(-124.0, -114.5, num_buckets).tolist()\n",
    "    lat_buckets = np.linspace(32.0, 42, num_buckets).tolist()\n",
    "    \n",
    "    b_long = fc.bucketized_column(fc.numeric_column('longitude'), long_buckets)  \n",
    "    b_lat = fc.bucketized_column(fc.numeric_column('latitude'), lat_buckets)\n",
    "    \n",
    "    feature_cross = fc.crossed_column([b_lat, b_long], num_buckets**2)\n",
    "    \n",
    "    return [\n",
    "    # add embedding\n",
    "    fc.embedding_column(feature_cross, num_buckets//4), \n",
    "    # add other features \n",
    "    fc.numeric_column('median_income'),\n",
    "    fc.numeric_column('housing_median_age'),\n",
    "    fc.numeric_column('avg_rooms_per_house'),\n",
    "    fc.numeric_column('avg_persons_per_room'),\n",
    "    fc.numeric_column('avg_bedrooms_per_room')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Linear regressor with embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model 3\n",
    "linear_train_and_evaluate(output_dir='CHECKPOINTS/feat_eng_02/model_3', num_train_steps = 3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a very similar outcome as in our model 2. However, converting sparse input feature into dense input features through embeddings, **we can run the dataset now through a deep neural network with tensorflow - see model 4 below**\n",
    "\n",
    "<img src='images\\feature_eng2_model_3.PNG' width='600' height='600'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: DNN regressor with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'CHECKPOINTS/feat_eng_02/model_test2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000250BDFBCA58>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 100 or save_checkpoints_secs None.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:loss = 752.1631, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 100 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:39:27\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:39:28\n",
      "INFO:tensorflow:Saving dict for global step 100: average_loss = 95.287704, global_step = 100, label/mean = 2.071208, loss = 11999.192, prediction/mean = 11.161483\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-100\n",
      "INFO:tensorflow:global_step/sec: 19.2605\n",
      "INFO:tensorflow:loss = 49.43834, step = 101 (5.194 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:39:32\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:39:32\n",
      "INFO:tensorflow:Saving dict for global step 200: average_loss = 48.04264, global_step = 200, label/mean = 2.071208, loss = 6049.8145, prediction/mean = 8.410521\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 200: CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-200\n",
      "INFO:tensorflow:global_step/sec: 30.5262\n",
      "INFO:tensorflow:loss = 43.27358, step = 201 (3.277 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 300 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 45.7506\n",
      "INFO:tensorflow:loss = 36.34572, step = 301 (2.187 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 400 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:39:38\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:39:38\n",
      "INFO:tensorflow:Saving dict for global step 400: average_loss = 10.301182, global_step = 400, label/mean = 2.071208, loss = 1297.1859, prediction/mean = 4.9413576\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 400: CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-400\n",
      "INFO:tensorflow:global_step/sec: 27.845\n",
      "INFO:tensorflow:loss = 30.9362, step = 401 (3.593 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 48.2974\n",
      "INFO:tensorflow:loss = 23.295952, step = 501 (2.067 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 600 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:39:43\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:39:44\n",
      "INFO:tensorflow:Saving dict for global step 600: average_loss = 3.9492548, global_step = 600, label/mean = 2.0712082, loss = 497.31354, prediction/mean = 3.7136593\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 600: CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-600\n",
      "INFO:tensorflow:global_step/sec: 29.4765\n",
      "INFO:tensorflow:loss = 28.794666, step = 601 (3.391 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 700 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 44.625\n",
      "INFO:tensorflow:loss = 35.743443, step = 701 (2.242 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 800 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:39:50\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:39:50\n",
      "INFO:tensorflow:Saving dict for global step 800: average_loss = 1.3876042, global_step = 800, label/mean = 2.071208, loss = 174.73535, prediction/mean = 2.8850005\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 800: CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-800\n",
      "INFO:tensorflow:global_step/sec: 23.5626\n",
      "INFO:tensorflow:loss = 30.354374, step = 801 (4.245 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 900 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:39:54\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-900\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:39:54\n",
      "INFO:tensorflow:Saving dict for global step 900: average_loss = 1.0842471, global_step = 900, label/mean = 2.0712082, loss = 136.53482, prediction/mean = 2.6870983\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 900: CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-900\n",
      "INFO:tensorflow:global_step/sec: 23.4937\n",
      "INFO:tensorflow:loss = 41.631817, step = 901 (4.255 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 47.5121\n",
      "INFO:tensorflow:loss = 28.551834, step = 1001 (2.104 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1100 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:39:59\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:40:00\n",
      "INFO:tensorflow:Saving dict for global step 1100: average_loss = 0.66366404, global_step = 1100, label/mean = 2.071208, loss = 83.57251, prediction/mean = 2.416844\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1100: CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-1100\n",
      "INFO:tensorflow:global_step/sec: 27.3218\n",
      "INFO:tensorflow:loss = 33.345398, step = 1101 (3.667 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1200 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 49.4177\n",
      "INFO:tensorflow:loss = 27.440178, step = 1201 (2.019 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1300 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:40:05\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-1300\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:40:06\n",
      "INFO:tensorflow:Saving dict for global step 1300: average_loss = 0.55948585, global_step = 1300, label/mean = 2.071208, loss = 70.45377, prediction/mean = 2.157353\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1300: CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-1300\n",
      "INFO:tensorflow:global_step/sec: 27.1034\n",
      "INFO:tensorflow:loss = 41.97641, step = 1301 (3.691 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1400 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:40:10\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-1400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:40:10\n",
      "INFO:tensorflow:Saving dict for global step 1400: average_loss = 0.52112645, global_step = 1400, label/mean = 2.0712082, loss = 65.62333, prediction/mean = 2.059156\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1400: CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-1400\n",
      "INFO:tensorflow:global_step/sec: 22.055\n",
      "INFO:tensorflow:loss = 37.399826, step = 1401 (4.533 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1500 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 41.809\n",
      "INFO:tensorflow:loss = 39.304016, step = 1501 (2.390 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1600 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:40:16\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-1600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:40:16\n",
      "INFO:tensorflow:Saving dict for global step 1600: average_loss = 0.49261189, global_step = 1600, label/mean = 2.071208, loss = 62.032608, prediction/mean = 2.0368786\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1600: CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-1600\n",
      "INFO:tensorflow:global_step/sec: 27.4012\n",
      "INFO:tensorflow:loss = 42.899025, step = 1601 (3.669 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1700 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 40.5099\n",
      "INFO:tensorflow:loss = 47.387005, step = 1701 (2.450 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1800 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:40:22\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-1800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:40:23\n",
      "INFO:tensorflow:Saving dict for global step 1800: average_loss = 0.49097914, global_step = 1800, label/mean = 2.071208, loss = 61.827003, prediction/mean = 1.9626484\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1800: CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-1800\n",
      "INFO:tensorflow:global_step/sec: 25.062\n",
      "INFO:tensorflow:loss = 29.143223, step = 1801 (3.992 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1900 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 39.2718\n",
      "INFO:tensorflow:loss = 36.234993, step = 1901 (2.544 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:40:28\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:40:29\n",
      "INFO:tensorflow:Saving dict for global step 2000: average_loss = 0.4144444, global_step = 2000, label/mean = 2.071208, loss = 52.189297, prediction/mean = 2.0646336\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-2000\n",
      "INFO:tensorflow:global_step/sec: 29.4407\n",
      "INFO:tensorflow:loss = 33.99643, step = 2001 (3.399 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2100 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 46.6468\n",
      "INFO:tensorflow:loss = 18.18399, step = 2101 (2.141 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2200 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:40:34\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-2200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:40:34\n",
      "INFO:tensorflow:Saving dict for global step 2200: average_loss = 0.4256487, global_step = 2200, label/mean = 2.071208, loss = 53.600204, prediction/mean = 2.0220973\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2200: CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-2200\n",
      "INFO:tensorflow:global_step/sec: 28.8525\n",
      "INFO:tensorflow:loss = 36.289417, step = 2201 (3.470 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2300 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 38.0429\n",
      "INFO:tensorflow:loss = 27.85291, step = 2301 (2.622 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2400 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:40:41\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-2400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:40:41\n",
      "INFO:tensorflow:Saving dict for global step 2400: average_loss = 0.46356255, global_step = 2400, label/mean = 2.0712082, loss = 58.374542, prediction/mean = 1.8511859\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2400: CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.9641\n",
      "INFO:tensorflow:loss = 48.34984, step = 2401 (4.177 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2500 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 36.7425\n",
      "INFO:tensorflow:loss = 38.081932, step = 2501 (2.719 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2600 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:40:49\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-2600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:40:49\n",
      "INFO:tensorflow:Saving dict for global step 2600: average_loss = 0.4642874, global_step = 2600, label/mean = 2.0712082, loss = 58.46582, prediction/mean = 1.8949486\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2600: CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-2600\n",
      "INFO:tensorflow:global_step/sec: 18.2579\n",
      "INFO:tensorflow:loss = 23.669262, step = 2601 (5.479 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2700 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:global_step/sec: 39.9135\n",
      "INFO:tensorflow:loss = 35.44494, step = 2701 (2.503 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2800 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:40:57\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-2800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:40:58\n",
      "INFO:tensorflow:Saving dict for global step 2800: average_loss = 0.47108647, global_step = 2800, label/mean = 2.0712082, loss = 59.322, prediction/mean = 1.8552815\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2800: CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-2800\n",
      "INFO:tensorflow:global_step/sec: 16.1098\n",
      "INFO:tensorflow:loss = 27.213808, step = 2801 (6.210 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2900 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:41:02\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-2900\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:41:03\n",
      "INFO:tensorflow:Saving dict for global step 2900: average_loss = 0.40615878, global_step = 2900, label/mean = 2.071208, loss = 51.14592, prediction/mean = 1.9263445\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2900: CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-2900\n",
      "INFO:tensorflow:global_step/sec: 22.2508\n",
      "INFO:tensorflow:loss = 36.33554, step = 2901 (4.494 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (5 secs).\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-19:41:07\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-19:41:08\n",
      "INFO:tensorflow:Saving dict for global step 3000: average_loss = 0.52543366, global_step = 3000, label/mean = 2.071208, loss = 66.16572, prediction/mean = 1.8027315\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: CHECKPOINTS/feat_eng_02/model_test2\\model.ckpt-3000\n",
      "INFO:tensorflow:Loss for final step: 43.506927.\n"
     ]
    }
   ],
   "source": [
    "# run model 4\n",
    "dnn_train_and_evaluate(output_dir='CHECKPOINTS/feat_eng_02/model_test2', num_train_steps = 3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the embedding through a (somewhat arbirtrarily configured) four layer neural network improves again on the previously observed loss from the linear regressor. The deep NN is able to better capture non-linearities in the input data which the linear model simply cannot capture\n",
    "\n",
    "<img src='images\\feature_eng2_model_4.PNG' width='600' height='600'/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
